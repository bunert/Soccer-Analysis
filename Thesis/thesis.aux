\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand*{\memsetcounter}[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\changetocdepth  {2}}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {chapter}{Abstract}{i}{Doc-Start}}
\@writefile{toc}{\contentsline {chapter}{Contents}{iii}{section*.1}}
\@writefile{toc}{\contentsline {chapter}{List of Figures}{v}{section*.2}}
\@writefile{toc}{\contentsline {chapter}{List of Tables}{vi}{section*.3}}
\citation{worldcup}
\citation{intel}
\citation{vizrt}
\citation{vizrt}
\citation{vizrt}
\citation{hawk}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {1}Introduction}{1}{chapter.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Freekick Analysis and Visualization example from Vizrt's sports graphics and analysis tool.\newline  }}{1}{figure.1.1}}
\newlabel{fig:freekick}{{\M@TitleReference {1.1}{Freekick Analysis and Visualization example from Vizrt's sports graphics and analysis tool.\newline  }}{1}{Freekick Analysis and Visualization example from Vizrt's sports graphics and analysis tool.\newline }{figure.1.1}{}}
\citation{openpose}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Focus of this Work}{2}{section.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.1}Thesis Organization}{2}{subsection.1.1.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1.2}Outlook on the Method}{2}{subsection.1.1.2}}
\citation{intel}
\citation{intelvideo}
\citation{intelcameras}
\citation{intelcameras}
\citation{xsens}
\citation{Nogueira2012MotionCF}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {2}Related Work}{5}{chapter.2}}
\newlabel{chap:relatedWork}{{\M@TitleReference {2}{Related Work}}{5}{Related Work}{chapter.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces High-definiton 5K cameras locations for the Intel True View technology solution in a soccer stadium.\newline  }}{5}{figure.2.1}}
\newlabel{fig:intelcameras}{{\M@TitleReference {2.1}{High-definiton 5K cameras locations for the Intel True View technology solution in a soccer stadium.\newline  }}{5}{High-definiton 5K cameras locations for the Intel True View technology solution in a soccer stadium.\newline }{figure.2.1}{}}
\citation{xsens}
\citation{Nogueira2012MotionCF}
\citation{motionWiki}
\citation{magnetic}
\citation{motionWiki}
\citation{xsens}
\citation{xsens}
\citation{xsens}
\citation{motioncapturetechnologies}
\citation{xsensmessi}
\citation{xsensmessi}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Motion Capture}{6}{section.2.1}}
\@writefile{toc}{\contentsline {subsubsection}{Marker-Based Motion Capture}{6}{section*.4}}
\citation{motioncapturetechnologies}
\citation{microsoft}
\citation{microsoft}
\citation{microsoft}
\citation{microsoft}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Messi in Xsens motion capture suit for FIFA 16 to animate his dribbling style as realistically as possible. \newline  }}{7}{figure.2.2}}
\newlabel{fig:messi}{{\M@TitleReference {2.2}{Messi in Xsens motion capture suit for FIFA 16 to animate his dribbling style as realistically as possible. \newline  }}{7}{Messi in Xsens motion capture suit for FIFA 16 to animate his dribbling style as realistically as possible. \newline }{figure.2.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{Markerless Motion Capture}{7}{section*.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Overview for the 3D positions reconstruction from one single depth image.\newline  }}{7}{figure.2.3}}
\newlabel{fig:messi}{{\M@TitleReference {2.3}{Overview for the 3D positions reconstruction from one single depth image.\newline  }}{7}{Overview for the 3D positions reconstruction from one single depth image.\newline }{figure.2.3}{}}
\citation{openpose_paper}
\citation{deepcut}
\citation{openpose_paper}
\citation{openpose_example}
\citation{openpose_example}
\citation{depth_estimation}
\citation{depth_map}
\citation{3dpose}
\citation{deepcut}
\citation{smpl}
\citation{3dpose}
\citation{3dpose}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Human Poses Estimation}{8}{section.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces human 2D pose estimation example with OpenPose\newline  }}{8}{figure.2.4}}
\newlabel{fig:openpose_example}{{\M@TitleReference {2.4}{human 2D pose estimation example with OpenPose\newline  }}{8}{human 2D pose estimation example with OpenPose\newline }{figure.2.4}{}}
\citation{tabletop}
\citation{tabletop}
\citation{tabletop}
\citation{detectron}
\citation{openpose_paper}
\citation{segmentation}
\citation{tabletop}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces To the 2D joints of the original image (not shown) a \textit  {SMLP} model is fitted as seen in the middle and on the right side the resulting 3D model is rendered from a different viewpoint. \newline  }}{9}{figure.2.5}}
\newlabel{fig:3dpose_example}{{\M@TitleReference {2.5}{To the 2D joints of the original image (not shown) a \textit  {SMLP} model is fitted as seen in the middle and on the right side the resulting 3D model is rendered from a different viewpoint. \newline  }}{9}{To the 2D joints of the original image (not shown) a \textit {SMLP} model is fitted as seen in the middle and on the right side the resulting 3D model is rendered from a different viewpoint. \newline }{figure.2.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Soccer on Your Tabletop}{9}{section.2.3}}
\newlabel{tabletop}{{\M@TitleReference {2.3}{Soccer on Your Tabletop}}{9}{Soccer on Your Tabletop}{section.2.3}{}}
\citation{r-cnn}
\citation{retinenet}
\citation{pytorch}
\citation{tabletop}
\citation{camerablog}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Overview of their reconstruction pipeline. In the first step the players from the input frame are analyzed and the camera calibrated. Through the player analysis they segment the player and reconstruct the depth map on the pitch per player. At the end they render the scene in 3D for a complete scene reconstruction. \newline  }}{10}{figure.2.6}}
\newlabel{fig:tabletop}{{\M@TitleReference {2.6}{Overview of their reconstruction pipeline. In the first step the players from the input frame are analyzed and the camera calibrated. Through the player analysis they segment the player and reconstruct the depth map on the pitch per player. At the end they render the scene in 3D for a complete scene reconstruction. \newline  }}{10}{Overview of their reconstruction pipeline. In the first step the players from the input frame are analyzed and the camera calibrated. Through the player analysis they segment the player and reconstruct the depth map on the pitch per player. At the end they render the scene in 3D for a complete scene reconstruction. \newline }{figure.2.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{Building Blocks}{10}{section*.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Detectron}{10}{subsection.2.3.1}}
\newlabel{sec:detectron}{{\M@TitleReference {2.3.1}{Detectron}}{10}{Detectron}{subsection.2.3.1}{}}
\citation{opencv}
\citation{ransac}
\citation{opencv}
\citation{canny}
\citation{canny}
\citation{distance_transform}
\citation{tabletop}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Calibration}{11}{subsection.2.3.2}}
\newlabel{sec:tablecalibration}{{\M@TitleReference {2.3.2}{Calibration}}{11}{Calibration}{subsection.2.3.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{Manual Initialization}{11}{section*.7}}
\citation{openpose_paper}
\citation{openpose}
\citation{openpose}
\@writefile{toc}{\contentsline {subsubsection}{Calibration Propagation}{12}{section*.8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}OpenPose}{12}{subsection.2.3.3}}
\newlabel{sec:openpose}{{\M@TitleReference {2.3.3}{OpenPose}}{12}{OpenPose}{subsection.2.3.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Numbering of the 18 keypoint of the COCO pose format from \textit  {OpenPose}. \newline  }}{12}{figure.2.7}}
\newlabel{fig:coco}{{\M@TitleReference {2.7}{Numbering of the 18 keypoint of the COCO pose format from \textit  {OpenPose}. \newline  }}{12}{Numbering of the 18 keypoint of the COCO pose format from \textit {OpenPose}. \newline }{figure.2.7}{}}
\citation{openpose_paper}
\citation{deepcut}
\citation{openpose_paper}
\citation{openpose_paper}
\citation{openpose_paper}
\citation{openpose_paper}
\@writefile{toc}{\contentsline {subsubsection}{Algortihm}{13}{section*.9}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces \textit  {OpenPose} Pipeline Overview. The input image (a) is processed to produce the confidence maps (b) and part affinity fields (c) using a CNN. The result is formulated as a bipartite matching problem (d) in order to solve the part association (e).\newline  }}{13}{figure.2.8}}
\newlabel{fig:openpose_overview}{{\M@TitleReference {2.8}{\textit  {OpenPose} Pipeline Overview. The input image (a) is processed to produce the confidence maps (b) and part affinity fields (c) using a CNN. The result is formulated as a bipartite matching problem (d) in order to solve the part association (e).\newline  }}{13}{\textit {OpenPose} Pipeline Overview. The input image (a) is processed to produce the confidence maps (b) and part affinity fields (c) using a CNN. The result is formulated as a bipartite matching problem (d) in order to solve the part association (e).\newline }{figure.2.8}{}}
\citation{filterpybook}
\citation{filterpygithub}
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces \textit  {OpenPose's} Part Association formulated as a matching problem with the use of part affinity fields. (a) shows the detected body parts which are then connected in a complete graph (b). The first relaxation reduces the graph to spanning tree skeletons (c) and the second relaxation decompose the graph into bipartit matching subproblems (d).\newline  }}{14}{figure.2.9}}
\newlabel{fig:openpose_mapping}{{\M@TitleReference {2.9}{\textit  {OpenPose's} Part Association formulated as a matching problem with the use of part affinity fields. (a) shows the detected body parts which are then connected in a complete graph (b). The first relaxation reduces the graph to spanning tree skeletons (c) and the second relaxation decompose the graph into bipartit matching subproblems (d).\newline  }}{14}{\textit {OpenPose's} Part Association formulated as a matching problem with the use of part affinity fields. (a) shows the detected body parts which are then connected in a complete graph (b). The first relaxation reduces the graph to spanning tree skeletons (c) and the second relaxation decompose the graph into bipartit matching subproblems (d).\newline }{figure.2.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.4}Depth Map Estimation}{14}{subsection.2.3.4}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Filterpy}{14}{section.2.4}}
\newlabel{sec:filterpy}{{\M@TitleReference {2.4}{Filterpy}}{14}{Filterpy}{section.2.4}{}}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {3}Method}{17}{chapter.3}}
\newlabel{chap:method}{{\M@TitleReference {3}{Method}}{17}{Method}{chapter.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Overview of the workflow. Each step gets described in detail during this chapter. The gray area is the process for each camera separately while in the blue area the different cameras are merged.}}{17}{figure.3.1}}
\newlabel{fig:overview}{{\M@TitleReference {3.1}{Overview of the workflow. Each step gets described in detail during this chapter. The gray area is the process for each camera separately while in the blue area the different cameras are merged.}}{17}{Overview of the workflow. Each step gets described in detail during this chapter. The gray area is the process for each camera separately while in the blue area the different cameras are merged}{figure.3.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Calibration}{17}{section.3.1}}
\newlabel{sec:calibration}{{\M@TitleReference {3.1}{Calibration}}{17}{Calibration}{section.3.1}{}}
\citation{triangulation}
\citation{triangulation}
\citation{triangulation}
\citation{triangulation}
\citation{kalmanbook}
\citation{filterpybook}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}Camera Matrix}{18}{subsection.3.1.1}}
\newlabel{sec:cameramatrix}{{\M@TitleReference {3.1.1}{Camera Matrix}}{18}{Camera Matrix}{subsection.3.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}Line Detection}{18}{subsection.3.1.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Player Detection}{18}{section.3.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}2D Pose Estimation}{18}{section.3.3}}
\newlabel{sec:poseestimation}{{\M@TitleReference {3.3}{2D Pose Estimation}}{18}{2D Pose Estimation}{section.3.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}2D Refinement \& mapping}{18}{section.3.4}}
\newlabel{sec:2drefinement}{{\M@TitleReference {3.4}{2D Refinement \& mapping}}{18}{2D Refinement \& mapping}{section.3.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}3D Pose Fusion}{18}{section.3.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Triangulation}{18}{subsection.3.5.1}}
\citation{kalmanbook}
\citation{kalmanbook}
\citation{kalmanbook}
\citation{filterpybook}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Triangulation visualization of two images with the camera's focal length $O_1$ and $O_2$. The ideal case with perfect measurements in green and the case of measurements with arbitrary accuracy in blue.\newline  }}{19}{figure.3.2}}
\newlabel{fig:triangulation}{{\M@TitleReference {3.2}{Triangulation visualization of two images with the camera's focal length $O_1$ and $O_2$. The ideal case with perfect measurements in green and the case of measurements with arbitrary accuracy in blue.\newline  }}{19}{Triangulation visualization of two images with the camera's focal length $O_1$ and $O_2$. The ideal case with perfect measurements in green and the case of measurements with arbitrary accuracy in blue.\newline }{figure.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.2}Extended Kalman Filter}{19}{subsection.3.5.2}}
\newlabel{sec:EKF}{{\M@TitleReference {3.5.2}{Extended Kalman Filter}}{19}{Extended Kalman Filter}{subsection.3.5.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Complete picture of the calculations during the two-step process of the Extended Kalman Filter. For the Initialization the values of the first state vector and the error covariance are needed. A new measurement vector is given to the filter for each Measurement Update step.\newline  }}{20}{figure.3.3}}
\newlabel{fig:kalmanprocess}{{\M@TitleReference {3.3}{Complete picture of the calculations during the two-step process of the Extended Kalman Filter. For the Initialization the values of the first state vector and the error covariance are needed. A new measurement vector is given to the filter for each Measurement Update step.\newline  }}{20}{Complete picture of the calculations during the two-step process of the Extended Kalman Filter. For the Initialization the values of the first state vector and the error covariance are needed. A new measurement vector is given to the filter for each Measurement Update step.\newline }{figure.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.3}Designing the EKF}{20}{subsection.3.5.3}}
\@writefile{toc}{\contentsline {subsubsection}{State and Measurement}{20}{section*.10}}
\@writefile{toc}{\contentsline {subsubsection}{Process Model}{21}{section*.11}}
\newlabel{eq:state}{{3.7}{21}{Process Model}{equation.3.5.7}{}}
\newlabel{eq:covariance}{{3.8}{21}{Process Model}{equation.3.5.8}{}}
\citation{kalmanbook}
\@writefile{toc}{\contentsline {subsubsection}{Noise}{22}{section*.12}}
\@writefile{toc}{\contentsline {subsubsection}{Kalman gain and Error covariance}{22}{section*.13}}
\newlabel{eq:covariance2}{{3.11}{22}{Kalman gain and Error covariance}{equation.3.5.11}{}}
\citation{filterpydoc}
\@writefile{toc}{\contentsline {subsubsection}{Measurement Model}{23}{section*.14}}
\newlabel{eq:homogenous}{{3.16}{23}{Measurement Model}{equation.3.5.16}{}}
\newlabel{eq:screencoordinates}{{3.17}{24}{Measurement Model}{equation.3.5.17}{}}
\@writefile{toc}{\contentsline {subsubsection}{Jacobian Matrix H}{24}{section*.15}}
\newlabel{sec:jacobian}{{\M@TitleReference {3.5.3}{Jacobian Matrix H}}{24}{Jacobian Matrix H}{section*.15}{}}
\citation{filterpydoc}
\newlabel{eq:partial}{{3.22}{25}{Jacobian Matrix H}{equation.3.5.22}{}}
\@writefile{toc}{\contentsline {subsubsection}{State Initialization}{26}{section*.16}}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {4}Results and Discussion}{27}{chapter.4}}
\newlabel{chap:results}{{\M@TitleReference {4}{Results and Discussion}}{27}{Results and Discussion}{chapter.4}{}}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {5}Conclusion}{29}{chapter.5}}
\newlabel{chap:conclusion}{{\M@TitleReference {5}{Conclusion}}{29}{Conclusion}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Future Work}{29}{section.5.1}}
\bibstyle{plain}
\bibdata{refs}
\bibcite{3dpose}{1}
\bibcite{openpose_paper}{2}
\bibcite{openpose_example}{3}
\bibcite{opencv}{4}
\bibcite{canny}{5}
\bibcite{distance_transform}{6}
\bibcite{depth_map}{7}
\bibcite{worldcup}{8}
\bibcite{detectron}{9}
\bibcite{depth_estimation}{10}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{31}{section*.18}}
\bibcite{intel}{11}
\bibcite{intelvideo}{12}
\bibcite{filterpybook}{13}
\bibcite{filterpydoc}{14}
\bibcite{filterpygithub}{15}
\bibcite{retinenet}{16}
\bibcite{smpl}{17}
\bibcite{magnetic}{18}
\bibcite{hawk}{19}
\bibcite{Nogueira2012MotionCF}{20}
\bibcite{openpose}{21}
\bibcite{deepcut}{22}
\bibcite{motioncapturetechnologies}{23}
\bibcite{pytorch}{24}
\bibcite{tabletop}{25}
\bibcite{r-cnn}{26}
\bibcite{microsoft}{27}
\bibcite{camerablog}{28}
\bibcite{intelcameras}{29}
\bibcite{vizrt}{30}
\bibcite{kalmanbook}{31}
\bibcite{motionWiki}{32}
\bibcite{ransac}{33}
\bibcite{triangulation}{34}
\bibcite{xsensmessi}{35}
\bibcite{xsens}{36}
\bibcite{segmentation}{37}
\memsetcounter{lastsheet}{43}
\memsetcounter{lastpage}{35}
